{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Simulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'parallel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b5baadd3fa9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'parallel'"
     ]
    }
   ],
   "source": [
    "from IPython.parallel import Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rc = Client()\n",
    "dv = rc[:]\n",
    "\n",
    "\n",
    "@dv.remote(block = True)\n",
    "def GetSimulationResults():\n",
    "    # Most Basic\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib as mpl\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from os import path\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    from scipy.stats import norm\n",
    "    import scipy.stats as ss\n",
    "    import copy\n",
    "    import warnings\n",
    "    warnings.simplefilter('error')\n",
    "    import datetime\n",
    "\n",
    "    # Filter Specific Functionalities\n",
    "    from filterpy.kalman import UnscentedKalmanFilter\n",
    "    from filterpy.common import Q_discrete_white_noise\n",
    "    from filterpy.kalman import MerweScaledSigmaPoints\n",
    "\n",
    "    # Gradient Based\n",
    "    import autograd.numpy as a_np\n",
    "    import autograd.scipy.stats as a_ss\n",
    "    from autograd import grad, multigrad_dict, elementwise_grad, jacobian\n",
    "\n",
    "    # Self Defined functions5\n",
    "    from DataMaker_New import dataCleaner_new\n",
    "    from ESN import EchoState\n",
    "    from Loss_diag_updateV import loss\n",
    "    from GenerateSimulatedData import make_simulated_data\n",
    "\n",
    "    u_dim = 8\n",
    "    topK = 10\n",
    "    n_scenario = 1\n",
    "    np.random.seed(1234)\n",
    "    train_list, valid_list, test_list, true_vol = make_simulated_data(n_scenarios= n_scenario, n_steps=200 ,true_vol_std=0.01, topK=topK, init_price=2000, u_dim=u_dim)\n",
    "\n",
    "    train_dates = list(train_list[0].keys())\n",
    "    valid_dates = list(valid_list[0].keys())\n",
    "    test_dates = list(test_list[0].keys())\n",
    "    num_train_day = max(train_dates)-min(train_dates)+1\n",
    "    num_valid_day = max(valid_dates)-min(valid_dates)+1\n",
    "    num_test_day = max(test_dates)-min(test_dates)+1\n",
    "    num_train_obs = num_train_day*topK \n",
    "    num_valid_obs = num_valid_day*topK\n",
    "    num_test_obs = num_test_day*topK \n",
    "\n",
    "    print(\"Attached {} train days; {} train observations\".format(num_train_day, num_train_obs))\n",
    "    print(\"Attached {} valid days; {} valid observations\".format(num_valid_day, num_valid_obs))\n",
    "    print(\"Attached {} test days; {} test observations\".format(num_test_day, num_test_obs))\n",
    "\n",
    "    # Define transition Dynamics\n",
    "    # Positional requirement, no real effect, will be replaced by ESN and BS defined further down\n",
    "    def fx(x, dt):\n",
    "        return x*dt\n",
    "    def hx(x):\n",
    "        return x\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return np.divide(1, 1+np.exp(-x))\n",
    "\n",
    "\n",
    "    def ESNf(theta_now, dt, **fx_args):\n",
    "        \"\"\"\n",
    "        :params theta_now theta_t\n",
    "\n",
    "        **fx_args\n",
    "        :params G reservoir transition matrix\n",
    "        :params G_in input translation matrix\n",
    "        :params b reservoir bias vector\n",
    "        :params u_quad_now u_t^2\n",
    "        \"\"\"\n",
    "        G = fx_args[\"G\"]\n",
    "        G_in = fx_args[\"G_in\"]\n",
    "        b = fx_args[\"b\"]\n",
    "        u_quad_now = fx_args[\"u_quad_now\"]\n",
    "        theta_next = sigmoid(np.matmul(G, theta_now) + np.matmul(G_in, u_quad_now) + b)\n",
    "        return theta_next\n",
    "\n",
    "\n",
    "    def BSf(theta_t, **hx_args):\n",
    "        \"\"\"\n",
    "        :params theta_t current state vector\n",
    "\n",
    "        **hx_args\n",
    "        :params p_t current asset price\n",
    "        :params r_t current asset price\n",
    "        :params K_t strike price, 1d vector\n",
    "        :params T_t maturity time, 1d vector\n",
    "        \"\"\"\n",
    "        p_t = hx_args[\"p_t\"]\n",
    "        r_t = hx_args[\"r_t\"]\n",
    "        K_t = hx_args[\"K_t\"]\n",
    "        T_t = hx_args[\"T_t\"]\n",
    "\n",
    "        volatility_std = np.average(theta_t)\n",
    "        volatility_var = np.power(volatility_std, 2)\n",
    "\n",
    "        dividor = np.sqrt(volatility_var * T_t)\n",
    "        d_pls = (np.log(p_t/K_t) + np.multiply(r_t+volatility_var/2, T_t)) / dividor\n",
    "        d_mns = (np.log(p_t/K_t) + np.multiply(r_t-volatility_var/2, T_t)) / dividor\n",
    "        y_t = np.multiply(p_t, norm.cdf(d_pls)) - np.multiply(np.multiply(K_t, np.exp(-r_t*T_t)), norm.cdf(d_mns))\n",
    "        return y_t\n",
    "\n",
    "    def is_pos_def(x):\n",
    "        return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "    def getCoverage(mean, std, truth):\n",
    "        check_points = np.arange(5, 100, 5) / 100\n",
    "\n",
    "\n",
    "        samples = np.random.normal( mean, std, (50, 100) )\n",
    "\n",
    "        coverage_for_1_observation = []\n",
    "        for check_point in check_points:\n",
    "            lower = np.quantile(samples, 0.5-check_point/2, axis=1 )\n",
    "            upper = np.quantile(samples, 0.5+check_point/2, axis=1 ) \n",
    "            coverage_for_1_observation.append( float(np.count_nonzero( np.logical_and( lower < truth , truth < upper ) ) / 50 ) )\n",
    "        return coverage_for_1_observation\n",
    "\n",
    "    np.random.seed(1234)\n",
    "    gradient = grad(loss)\n",
    "\n",
    "\n",
    "    forward_k = 20\n",
    "\n",
    "    error_for_all_scenario = []\n",
    "    best_itr_for_all_scenario = []\n",
    "    best_train_itr_for_all_scenario = []\n",
    "    best_valid_itr_for_all_scenario= []\n",
    "    params_for_all_scenario = []\n",
    "    ms_s_for_all_scenario = []\n",
    "    Cs_s_for_all_scenario = []\n",
    "    pred_Cs_for_all_scenario = []\n",
    "\n",
    "    train_pred_ms_for_all_scenario = []\n",
    "    pred_ms_for_all_scenario = []\n",
    "\n",
    "\n",
    "    theta_dim = 8\n",
    "    print(\"theta_dim = {}\".format(theta_dim))   \n",
    "\n",
    "    for scenario_idx in range(n_scenario):\n",
    "        best_valid_error = 999\n",
    "        best_valid_itr = 0\n",
    "\n",
    "        train_data = train_list[scenario_idx]\n",
    "        valid_data = valid_list[scenario_idx]\n",
    "        test_data = test_list[scenario_idx]\n",
    "\n",
    "        step = 0.03\n",
    "        m_t_1 = [np.array([0]), np.array([0]), np.array([0]), np.array([0]), np.array([0])]\n",
    "        v_t_1 = [np.array([0]), np.array([0]), np.array([0]), np.array([0]), np.array([0])]\n",
    "        beta_1 = 0.9\n",
    "        beta_2 = 0.999\n",
    "        epsillon = 1e-8\n",
    "\n",
    "        print(\"The {}th scenario\".format(scenario_idx+1))\n",
    "        alpha = 0.005\n",
    "        connectivity = 0.4\n",
    "        spectral_radius = 1.2\n",
    "        bday_p_year = 252\n",
    "        bias = -2.51\n",
    "\n",
    "        v_scale = 4.0\n",
    "        w = 0.0001\n",
    "\n",
    "        # initialize ESN dynamics\n",
    "        ESN = EchoState(theta_dim, u_dim, connectivity, spectral_radius, bias)\n",
    "        ESN.G_in *= 2\n",
    "        v = v_scale\n",
    "\n",
    "        last_avg_error = 100\n",
    "        best_itr = 0\n",
    "        best_train_error = 100\n",
    "        best_train_itr = 0\n",
    "\n",
    "        #%%%%%% Error trajectories\n",
    "\n",
    "        test_error_traj = []\n",
    "        params_traj = []\n",
    "        ms_s_traj = []\n",
    "        Cs_s_traj = []\n",
    "\n",
    "        train_pred_ms_traj = []\n",
    "        pred_ms_traj = []\n",
    "        pred_Cs_traj = []\n",
    "\n",
    "        for em_itr in range(25):\n",
    "            dt=1\n",
    "            points = MerweScaledSigmaPoints(theta_dim, alpha=.001, beta=2., kappa=0)\n",
    "            ukf = UnscentedKalmanFilter(dim_x=ESN.theta_dim, dim_z=topK, dt=1, fx=fx, hx=hx, points=points)\n",
    "            ukf.x = np.ones(ESN.theta_dim)* 0.006 # initial state\n",
    "            ukf.P *= 0.01 # initial uncertainty\n",
    "            ukf.R = np.diag([v]*topK) # 1 standard\n",
    "            ukf.Q = np.eye(theta_dim)*w\n",
    "\n",
    "            ms = [ukf.x.copy()]\n",
    "            Cs = [ukf.P.copy()]\n",
    "            u_quad_s = []\n",
    "            ps = []\n",
    "            rs = []\n",
    "            ys = []\n",
    "            Ks = []\n",
    "            us = []\n",
    "            Ts = []\n",
    "\n",
    "            all_days = sorted(list(train_data.keys()))\n",
    "            for day in all_days:\n",
    "                # get observable data\n",
    "                ## Stock Wise and market wise data\n",
    "                r_t = train_data[day][\"risk ir\"] \n",
    "                u_t = train_data[day][\"return\"].reshape([-1]) * math.sqrt(bday_p_year)\n",
    "                p_t = train_data[day][\"price\"]\n",
    "\n",
    "                ## Option wise data\n",
    "                y_t = train_data[day][\"option price\"]\n",
    "                K_t = train_data[day][\"Strike\"]\n",
    "                T_t = train_data[day][\"Exercise Time\"]\n",
    "\n",
    "                ukf.predict(fx = ESNf, G=ESN.G, G_in=ESN.G_in, b= ESN.b, u_quad_now=np.power(u_t,2))\n",
    "                ukf.update(y_t, hx=BSf, p_t=p_t, r_t=r_t, K_t=K_t, T_t=T_t)\n",
    "                ms.append(ukf.x_post.copy())\n",
    "                Cs.append(ukf.P_post.copy())\n",
    "                u_quad_s.append(np.power(u_t,2))\n",
    "                us.append(u_t)\n",
    "                ps.append(p_t)\n",
    "                rs.append(r_t)\n",
    "                ys.append(y_t)\n",
    "                Ks.append(K_t)\n",
    "                Ts.append(T_t)\n",
    "\n",
    "            ms = np.array(ms)\n",
    "            Cs = np.array(Cs)\n",
    "            ms_s, Cs_s, _, cvs_s = ukf.rts_smoother(ms, Cs, fx=ESNf, G=ESN.G, G_in=ESN.G_in, b=ESN.b, u_s=us)\n",
    "\n",
    "\n",
    "            params = [copy.copy(ESN.G), copy.copy(ESN.G_in), copy.copy(ESN.b), copy.copy(w), copy.copy(v)]\n",
    "\n",
    "\n",
    "            try:\n",
    "                curr_loss = loss(params,\n",
    "                                 ms_s, Cs_s, cvs_s,\n",
    "                                 u_quad_s,\n",
    "                                 ps, rs, Ks, Ts, ys,\n",
    "                                 num_train_obs,\n",
    "                                 reg=alpha)\n",
    "                curr_grad = gradient(params,\n",
    "                                     ms_s, Cs_s, cvs_s,\n",
    "                                     u_quad_s,\n",
    "                                     ps, rs, Ks, Ts, ys,\n",
    "                                     num_train_obs,\n",
    "                                     reg=alpha)\n",
    "\n",
    "    ######################## Adam Optimizer ###########################\n",
    "\n",
    "                m_t = [None, None, None, None, None]\n",
    "                v_t = [None, None, None, None, None]\n",
    "                m_t_hat = [None, None, None, None, None]\n",
    "                v_t_hat = [None, None, None, None, None]\n",
    "\n",
    "                m_t[0] = beta_1 * m_t_1[0] + (1-beta_1) * curr_grad[0]\n",
    "                v_t[0] = beta_2 * v_t_1[0] + (1-beta_2) * (curr_grad[0] * curr_grad[0])\n",
    "                m_t_hat[0] = m_t[0] / (1-beta_1 ** (em_itr+1))\n",
    "                v_t_hat[0] = v_t[0] / (1-beta_2 ** (em_itr+1))\n",
    "                params[0] -= step * m_t_hat[0] / (np.sqrt(v_t_hat[0]) + epsillon)\n",
    "\n",
    "                m_t[1] = beta_1 * m_t_1[1] + (1-beta_1) * curr_grad[1]\n",
    "                v_t[1] = beta_2 * v_t_1[1] + (1-beta_2) * (curr_grad[1] * curr_grad[1])\n",
    "                m_t_hat[1] = m_t[1] / (1-beta_1 ** (em_itr+1))\n",
    "                v_t_hat[1] = v_t[1] / (1-beta_2 ** (em_itr+1))\n",
    "                params[1] -= step * m_t_hat[1] / (np.sqrt(v_t_hat[1]) + epsillon)\n",
    "\n",
    "                m_t[2] = beta_1 * m_t_1[2] + (1-beta_1) * curr_grad[2]\n",
    "                v_t[2] = beta_2 * v_t_1[2] + (1-beta_2) * (curr_grad[2] * curr_grad[2])\n",
    "                m_t_hat[2] = m_t[2] / (1-beta_1 ** (em_itr+1))\n",
    "                v_t_hat[2] = v_t[2] / (1-beta_2 ** (em_itr+1))\n",
    "                params[2] -= step * m_t_hat[2] / (np.sqrt(v_t_hat[2]) + epsillon)\n",
    "\n",
    "                m_t[3] = beta_1 * m_t_1[3] + (1-beta_1) * curr_grad[3]\n",
    "                v_t[3] = beta_2 * v_t_1[3] + (1-beta_2) * (curr_grad[3] * curr_grad[3])\n",
    "                m_t_hat[3] = m_t[3] / (1-beta_1 ** (em_itr+1))\n",
    "                v_t_hat[3] = v_t[3] / (1-beta_2 ** (em_itr+1))\n",
    "                params[3] -= step * m_t_hat[3] / (np.sqrt(v_t_hat[3]) + epsillon)\n",
    "\n",
    "                m_t[4] = beta_1 * m_t_1[4] + (1-beta_1) * curr_grad[4]\n",
    "                v_t[4] = beta_2 * v_t_1[4] + (1-beta_2) * (curr_grad[4] * curr_grad[4])\n",
    "                m_t_hat[4] = m_t[4] / (1-beta_1 ** (em_itr+1))\n",
    "                v_t_hat[4] = v_t[4] / (1-beta_2 ** (em_itr+1))\n",
    "                params[4] -= step * m_t_hat[4] / (np.sqrt(v_t_hat[4]) + epsillon)\n",
    "\n",
    "                m_t = m_t_1\n",
    "                v_t = v_t_1\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "            except RuntimeWarning or LinAlgError or OverflowError or w <= 0:\n",
    "                print(\"set w to 1e-6 ensure positive\")\n",
    "                pass\n",
    "\n",
    "            ESN.G, ESN.G_in, ESN.b, _, __ = params\n",
    "            w = max(0.000001, params[3][0]) # Change form arraybox back to scalar\n",
    "            v = max(0.000001, params[4][0]) # Change form arraybox back to scalar\n",
    "\n",
    "\n",
    "    ################################################################### Training Performance\n",
    "\n",
    "            train_pred_ms = []\n",
    "            train_errors = []\n",
    "            np.delete(ms_s,0,0)\n",
    "            np.delete(Cs_s,0,0)\n",
    "            for i in range(0, len(ms_s)-1):\n",
    "\n",
    "                ukf.predict(fx = ESNf,  G=ESN.G, G_in=ESN.G_in, b= ESN.b, u_quad_now=u_quad_s[i])\n",
    "                train_pred_ms.append(np.average(ukf.x_prior))\n",
    "                pred_price = BSf(ukf.x_prior, p_t=ps[i], r_t=rs[i], K_t=Ks[i], T_t=Ts[i])\n",
    "                error = np.average(np.abs(ys[i]-pred_price) /ys[i])\n",
    "                train_errors.append(error)\n",
    "                ukf.update(ys[i], hx=BSf, p_t=ps[i], r_t=rs[i], K_t=Ks[i], T_t=Ts[i])\n",
    "\n",
    "            train_pred_ms_traj.append(train_pred_ms)\n",
    "            avg_train_error = np.average(train_errors)\n",
    "    ################################################################### Validation Performance\n",
    "            ukf.x = ms_s[-1]\n",
    "            ukf.P = Cs_s[-1]\n",
    "            valid_errors = []\n",
    "            pred_ms = []\n",
    "            pred_Cs = []\n",
    "\n",
    "            all_valid_days = sorted(list(valid_data.keys()))\n",
    "            for day in all_valid_days:\n",
    "                # get observable data\n",
    "                ## Stock Wise and market wise data\n",
    "                r_t = valid_data[day][\"risk ir\"]\n",
    "                u_t = valid_data[day][\"return\"].reshape([-1]) * math.sqrt(bday_p_year)\n",
    "                p_t = valid_data[day][\"price\"]\n",
    "\n",
    "                ## Option wise data\n",
    "                y_t = valid_data[day][\"option price\"]\n",
    "                K_t = valid_data[day][\"Strike\"]\n",
    "                T_t = valid_data[day][\"Exercise Time\"]\n",
    "\n",
    "                ukf.predict(fx = ESNf, G=ESN.G, G_in=ESN.G_in, b= ESN.b, u_quad_now=np.power(u_t,2))\n",
    "                pred_ms.append(ukf.x_prior)\n",
    "                pred_Cs.append(ukf.P_prior)\n",
    "                pred_price = BSf(ukf.x_prior, p_t=p_t, r_t=r_t, K_t=K_t, T_t=T_t)\n",
    "                error = np.average(np.abs(y_t-pred_price) /y_t)\n",
    "                valid_errors.append(error)\n",
    "\n",
    "                ukf.update(y_t, hx=BSf, p_t=p_t, r_t=r_t, K_t=K_t, T_t=T_t)\n",
    "\n",
    "            avg_valid_error = np.average(valid_errors) \n",
    "\n",
    "    ################################################################### Testing Performance\n",
    "\n",
    "            # forward K step prediction\n",
    "            k_step_test_error = []\n",
    "\n",
    "            test_k_step_pred_ms = {}\n",
    "            test_k_step_pred_Cs = {}\n",
    "\n",
    "            for k in range(1, min(forward_k+1, num_test_day+1)): \n",
    "\n",
    "                test_k_step_pred_ms[k] = []\n",
    "                test_k_step_pred_Cs[k] = []\n",
    "\n",
    "                test_errors = []            \n",
    "                all_test_days = sorted(list(test_data.keys()))\n",
    "\n",
    "                for idx in range(len(all_test_days) - k):\n",
    "\n",
    "                    ukf_pred = copy.deepcopy(ukf)\n",
    "\n",
    "                    # For loop for k predictions forward\n",
    "                    for shift in range(k) :\n",
    "                        # get observable data\n",
    "                        ## Stock Wise and market wise data\n",
    "                        r_t = test_data[all_test_days[idx+shift]][\"risk ir\"]\n",
    "                        u_t = test_data[all_test_days[idx+shift]][\"return\"].reshape([-1]) * math.sqrt(bday_p_year)\n",
    "                        p_t = test_data[all_test_days[idx+shift]][\"price\"]\n",
    "\n",
    "                        ## Option wise data\n",
    "                        y_t = test_data[all_test_days[idx+shift]][\"option price\"]\n",
    "                        K_t = test_data[all_test_days[idx+shift]][\"Strike\"]\n",
    "                        T_t = test_data[all_test_days[idx+shift]][\"Exercise Time\"]\n",
    "\n",
    "                        ukf_pred.predict(fx = ESNf, G=ESN.G, G_in=ESN.G_in, b= ESN.b, u_quad_now=np.power(u_t,2))\n",
    "\n",
    "\n",
    "                    test_k_step_pred_ms[k].append(ukf_pred.x_prior)\n",
    "                    test_k_step_pred_Cs[k].append(ukf_pred.P_prior)\n",
    "\n",
    "\n",
    "                    pred_price = BSf(ukf_pred.x_prior, p_t=p_t, r_t=r_t, K_t=K_t, T_t=T_t)\n",
    "                    error = np.average(np.abs(y_t-pred_price) /y_t)\n",
    "                    test_errors.append(error)\n",
    "\n",
    "\n",
    "                    # shift base one step forward\n",
    "                    r_t = test_data[all_test_days[idx]][\"risk ir\"] \n",
    "                    u_t = test_data[all_test_days[idx]][\"return\"].reshape([-1]) * math.sqrt(bday_p_year)\n",
    "                    p_t = test_data[all_test_days[idx]][\"price\"]\n",
    "\n",
    "                    ## Option wise data\n",
    "                    y_t = test_data[all_test_days[idx]][\"option price\"]\n",
    "                    K_t = test_data[all_test_days[idx]][\"Strike\"]\n",
    "                    T_t = test_data[all_test_days[idx]][\"Exercise Time\"]\n",
    "\n",
    "                    ukf.predict(fx = ESNf, G=ESN.G, G_in=ESN.G_in, b= ESN.b, u_quad_now=np.power(u_t,2))\n",
    "                    ukf.update(y_t, hx=BSf, p_t=p_t, r_t=r_t, K_t=K_t, T_t=T_t)\n",
    "\n",
    "                if test_errors != []:\n",
    "                    avg_test_error = np.average(test_errors)\n",
    "                    k_step_test_error.append(avg_test_error)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "\n",
    "    ################################################################### Show details\n",
    "            print(\"EM Iter {} | Loss {:.4f} | Train Error {:.4f} | Val Error {:.4f} | Test 1-Error {:.4f} | Test max-Error {:.4f} |\"  \n",
    "                  \" Dyn var {:.2f} | Obs var {:.2f}\".format(em_itr, curr_loss,\n",
    "                                                            avg_train_error, avg_valid_error, k_step_test_error[0], k_step_test_error[-1],\n",
    "                                                            w, v))\n",
    "\n",
    "            # Get best validation itr\n",
    "            if best_valid_error > avg_valid_error:\n",
    "                best_valid_error = avg_valid_error\n",
    "                best_valid_itr = em_itr\n",
    "\n",
    "            if last_avg_error < avg_valid_error and em_itr-best_itr >= 10:\n",
    "                pass \n",
    "            elif last_avg_error < avg_valid_error and em_itr-best_itr < 10:\n",
    "                pass\n",
    "            elif last_avg_error > avg_valid_error and em_itr-best_itr < 10:\n",
    "                last_avg_error = avg_valid_error\n",
    "                model_performance = avg_test_error\n",
    "                best_itr = em_itr\n",
    "\n",
    "            if best_train_error > avg_train_error and em_itr-best_train_itr < 10:\n",
    "                best_train_error = avg_train_error\n",
    "                best_train_itr = em_itr\n",
    "            elif best_train_error < avg_train_error:\n",
    "                step = 0.002\n",
    "\n",
    "            test_error_traj.append(k_step_test_error)\n",
    "            params_traj.append(copy.deepcopy(params))\n",
    "            ms_s_traj.append(ms_s)\n",
    "            Cs_s_traj.append(Cs_s)\n",
    "            pred_ms_traj.append(test_k_step_pred_ms)\n",
    "            pred_Cs_traj.append(test_k_step_pred_Cs)\n",
    "\n",
    "        error_for_all_scenario.append(test_error_traj)\n",
    "        best_itr_for_all_scenario.append(best_itr)\n",
    "        best_train_itr_for_all_scenario.append(best_train_itr)\n",
    "        best_valid_itr_for_all_scenario.append(best_valid_itr)\n",
    "        params_for_all_scenario.append(params_traj)\n",
    "        ms_s_for_all_scenario.append(ms_s_traj)\n",
    "        Cs_s_for_all_scenario.append(Cs_s_traj)\n",
    "        pred_ms_for_all_scenario.append(pred_ms_traj)\n",
    "        pred_Cs_for_all_scenario.append(pred_Cs_traj)\n",
    "        train_pred_ms_for_all_scenario.append(train_pred_ms_traj)\n",
    "\n",
    "        print(\"best val error: {} at {}th iteration, Model Performance: {} | theta_dim = {}\".format(last_avg_error,\n",
    "                                                                                                    best_itr,\n",
    "                                                                                                    model_performance,\n",
    "                                                                                                    theta_dim))\n",
    "        print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "        \n",
    "    return best_valid_itr_for_all_scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetSimulationResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d38e0242a261>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'~/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.ipython'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cython'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cylib*so'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsitepackages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import site\n",
    "import shutil\n",
    "src = glob.glob(os.path.join(os.path.expanduser('~/'), '.ipython', 'cython', 'cylib*so'))[0]\n",
    "dst = site.getsitepackages()[0]\n",
    "shutil.copy(src, dst)\n",
    "\n",
    "\n",
    "with dv.sync_imports():\n",
    "    import cylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing sys on engine(s)\n",
      "Local:  ['something']\n",
      "\n",
      "Remote:  [['', '', 'D:\\\\Change\\\\Research\\\\StochasticPricingModelSayanMukherjee\\\\EchoStateNeuralStochasticVolatilityHestonModel\\\\experiment', 'C:\\\\Users\\\\zd26\\\\Anaconda3\\\\python37.zip', 'C:\\\\Users\\\\zd26\\\\Anaconda3\\\\DLLs', 'C:\\\\Users\\\\zd26\\\\Anaconda3\\\\lib', 'C:\\\\Users\\\\zd26\\\\Anaconda3', 'C:\\\\Users\\\\zd26\\\\Anaconda3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\zd26\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\zd26\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\zd26\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\zd26\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions']]\n"
     ]
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "\n",
    "rc = Client()\n",
    "dview = rc[:]\n",
    "\n",
    "with dview.sync_imports():\n",
    "    import sys\n",
    "    sys.path[:] = ['something']\n",
    "\n",
    "def parallel(x):\n",
    "    import sys\n",
    "    return sys.path\n",
    "\n",
    "print('Local: ', sys.path)\n",
    "print()\n",
    "print('Remote: ', dview.map_sync(parallel, range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
