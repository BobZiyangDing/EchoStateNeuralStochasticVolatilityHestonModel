{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Basic\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from os import path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from scipy.stats import norm\n",
    "from scipy.linalg import block_diag\n",
    "import scipy.stats as ss\n",
    "import copy\n",
    "import warnings\n",
    "warnings.simplefilter('error')\n",
    "import datetime\n",
    "\n",
    "# Filter Specific Functionalities\n",
    "from filterpy.kalman import UnscentedKalmanFilter\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "from filterpy.kalman import MerweScaledSigmaPoints\n",
    "\n",
    "# Gradient Based\n",
    "import autograd.numpy as a_np\n",
    "import autograd.scipy.stats as a_ss\n",
    "from autograd import grad, multigrad_dict, elementwise_grad, jacobian\n",
    "\n",
    "# Self Defined functions5\n",
    "from DataMaker_New import dataCleaner_new\n",
    "from ESN import EchoState\n",
    "from Loss import loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attached 351 days of train data\n",
      "Attached 1755 train option observations\n",
      "Attached 1 days of validation data\n",
      "Attached 5 validation option observations\n",
      "Attached 23 days of test data\n",
      "Attached 115 test option observations\n"
     ]
    }
   ],
   "source": [
    "columns = [\"date\",\"exdate\",\"strike_price\",\"best_bid\",\"best_offer\",\"volume\",\"impl_volatility\"]\n",
    "start = datetime.datetime(2018, 1, 1)\n",
    "end = datetime.datetime(2019, 12, 31)\n",
    "train_valid_split = 0.936\n",
    "valid_test_split = 0.94\n",
    "u_dim = 5\n",
    "topK = 5\n",
    "cleaner = dataCleaner_new(columns, u_dim, topK, start, end, train_valid_split, valid_test_split)\n",
    "return_dict, price_dict = cleaner.make_return_price()\n",
    "risk_dict = cleaner.make_risk()\n",
    "train_data, valid_data, test_data = cleaner.make_final_data(price_dict, return_dict, risk_dict)\n",
    "num_train_day, num_train_obs = cleaner.get_train_num()\n",
    "num_valid_day, num_valid_obs = cleaner.get_valid_num()\n",
    "num_test_day, num_test_obs = cleaner.get_test_num()\n",
    "\n",
    "# train_data[np.datetime64('2019-01-02T00:00:00.000000000')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transition Dynamics\n",
    "# Positional requirement, no real effect, will be replaced by ESN and BS defined further down\n",
    "def fx(x, dt):\n",
    "    return x*dt\n",
    "def hx(x):\n",
    "    return x\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.divide(1, 1+np.exp(-x))\n",
    "\n",
    "\n",
    "def ESNf(inner_state, dt, **fx_args):\n",
    "    \"\"\"\n",
    "    :params inner_state [theta_t, G, G_in, b]\n",
    "    \n",
    "    **fx_args\n",
    "    :G_idx    start idx of G\n",
    "    :G_in_idx start idx of G_in\n",
    "    :b_idx    start idx of b\n",
    "    :params u_quad_now u_t^2\n",
    "    \"\"\"\n",
    "    G_idx = fx_args[\"G_idx\"]\n",
    "    G_in_idx = fx_args[\"G_in_idx\"]\n",
    "    b_idx = fx_args[\"b_idx\"]\n",
    "    u_quad_now = fx_args[\"u_quad_now\"].reshape([-1, 1])\n",
    "    \n",
    "   \n",
    "    theta_now = inner_state[: G_idx].reshape([-1,1])\n",
    "    G_flat = inner_state[G_idx : G_in_idx]\n",
    "    G_in_flat = inner_state[G_in_idx : b_idx] \n",
    "    \n",
    "    theta_dim = int(math.sqrt(len(G_flat)))\n",
    "    u_dim = int(len(G_in_flat) / theta_dim)\n",
    "    \n",
    "    \n",
    "    G = G_flat.reshape([theta_dim, theta_dim])\n",
    "    G_in = G_in_flat.reshape([theta_dim, u_dim])\n",
    "    b = inner_state[b_idx:].reshape([-1,1])\n",
    "    \n",
    "    \n",
    "    theta_next = sigmoid(np.matmul(G, theta_now) + np.matmul(G_in, u_quad_now) + b)\n",
    "    \n",
    "    \n",
    "    next_state = np.concatenate((theta_next.flatten(), G.flatten(), G_in.flatten(), b.flatten()))\n",
    "    \n",
    "    return next_state\n",
    "    \n",
    "\n",
    "def BSf(inner_state_t, **hx_args):\n",
    "    \"\"\"\n",
    "    :params theta_t current state vector\n",
    "    \n",
    "    **hx_args\n",
    "    :G_idx    start idx of G\n",
    "    :G_in_idx start idx of G_in\n",
    "    :b_idx    start idx of b\n",
    "    \n",
    "    :params p_t current asset price\n",
    "    :params r_t current asset price\n",
    "    :params K_t strike price, 1d vector\n",
    "    :params T_t maturity time, 1d vector\n",
    "    \"\"\"\n",
    "    G_idx = hx_args[\"G_idx\"]\n",
    "    G_in_idx = hx_args[\"G_in_idx\"]\n",
    "    b_idx = hx_args[\"b_idx\"]\n",
    "    \n",
    "    p_t = hx_args[\"p_t\"]\n",
    "    r_t = hx_args[\"r_t\"]\n",
    "    K_t = hx_args[\"K_t\"]\n",
    "    T_t = hx_args[\"T_t\"]\n",
    "    \n",
    "    theta_t = inner_state_t[: G_idx].reshape([-1,1])\n",
    "    G_flat = inner_state_t[G_idx : G_in_idx]\n",
    "    G_in_flat = inner_state_t[G_in_idx : b_idx] \n",
    "\n",
    "    \n",
    "    theta_dim = int(math.sqrt(len(G_flat)))\n",
    "    u_dim = int(len(G_in_flat) / theta_dim)\n",
    "    \n",
    "    G = G_flat.reshape([theta_dim, theta_dim])\n",
    "    G_in = G_in_flat.reshape([theta_dim, u_dim])\n",
    "    b = inner_state_t[b_idx:].reshape([-1,1])\n",
    "    \n",
    "    \n",
    "    volatility_std = np.average(theta_t)\n",
    "    volatility_var = np.power(volatility_std, 2)\n",
    "    \n",
    "    dividor = np.sqrt(volatility_var * T_t)\n",
    "    d_pls = (np.log(p_t/K_t) + np.multiply(r_t+volatility_var/2, T_t)) / dividor\n",
    "    d_mns = (np.log(p_t/K_t) + np.multiply(r_t-volatility_var/2, T_t)) / dividor\n",
    "    y_t = np.multiply(p_t, norm.cdf(d_pls)) - np.multiply(np.multiply(K_t, np.exp(-r_t*T_t)), norm.cdf(d_mns))\n",
    "    return y_t\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 睡觉专区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_dim = 10\n"
     ]
    },
    {
     "ename": "RuntimeWarning",
     "evalue": "overflow encountered in exp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeWarning\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c2cf5760f523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m                     ukf_pred.predict(fx = ESNf, \n\u001b[1;32m    179\u001b[0m                                      \u001b[0mG_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_in_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG_in_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                                      u_quad_now=np.power(u_t,2))\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/EchoStateNeuralStochasticVolatilityHestonModel/experiment/filterpy/kalman/UKF.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, dt, UT, fx, **fx_args)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;31m# calculate sigma points for given mean and covariance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_process_sigmas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfx_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m#and pass sigmas through the unscented transform to compute prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/EchoStateNeuralStochasticVolatilityHestonModel/experiment/filterpy/kalman/UKF.py\u001b[0m in \u001b[0;36mcompute_process_sigmas\u001b[0;34m(self, dt, fx, **fx_args)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmas_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfx_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbatch_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-89c4bf41ff64>\u001b[0m in \u001b[0;36mESNf\u001b[0;34m(inner_state, dt, **fx_args)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mtheta_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_now\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_quad_now\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-89c4bf41ff64>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeWarning\u001b[0m: overflow encountered in exp"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "gradient = grad(loss)\n",
    "num_iters = 10\n",
    "\n",
    "\n",
    "forward_k = 20\n",
    "\n",
    "error_for_all_theta_dim = []\n",
    "\n",
    "for theta_dim in np.arange(10, 11, 1):\n",
    "    \n",
    "    \n",
    "    G_idx = theta_dim\n",
    "    G_in_idx = G_idx + theta_dim**2\n",
    "    b_idx = G_in_idx + u_dim*theta_dim\n",
    "\n",
    "    \n",
    "    print(\"theta_dim = {}\".format(theta_dim))\n",
    "    connectivity = 0.4\n",
    "    spectral_radius = 0.98\n",
    "    bday_p_year = 252\n",
    "    bias = -2\n",
    "\n",
    "    v_scale = 100.0\n",
    "    target_var = 1e-6\n",
    "    chi_mu = math.sqrt(2)* math.gamma((theta_dim+1)/2) / math.gamma(theta_dim/2)\n",
    "    W_scale = target_var+chi_mu\n",
    "\n",
    "    # initialize ESN dynamics\n",
    "    ESN = EchoState(theta_dim, u_dim, connectivity, spectral_radius, bias)\n",
    "    total_dim = ESN.theta_dim + theta_dim**2 + u_dim*theta_dim + theta_dim\n",
    "    W = np.eye(total_dim)*W_scale\n",
    "    v = v_scale\n",
    "\n",
    "    last_avg_error = 100\n",
    "    best_itr = 0\n",
    "    best_train_error = 100\n",
    "    best_train_itr = 0\n",
    "    \n",
    "    dt=1\n",
    "    points = MerweScaledSigmaPoints(total_dim, alpha=.001, beta=2., kappa=0)\n",
    "    ukf = UnscentedKalmanFilter(dim_x=total_dim, dim_z=topK, dt=1, fx=fx, hx=hx, points=points)\n",
    "    initial_theta = np.ones(ESN.theta_dim)* 0.1\n",
    "    initial_state = np.concatenate((initial_theta, (ESN.G).flatten(), (ESN.G_in).flatten(), (ESN.b).flatten()))\n",
    "    ukf.x = initial_state # initial state\n",
    "    ukf.P *= 0.01 # initial uncertainty\n",
    "    ukf.R = np.diag([v]*topK) # 1 standard\n",
    "    ukf.Q = W\n",
    "    \n",
    "    for forward_backward_itr in range(num_iters):\n",
    "        ms = [ukf.x.copy()]\n",
    "        Cs = [ukf.P.copy()]\n",
    "        u_quad_s = []\n",
    "        ps = []\n",
    "        rs = []\n",
    "        ys = []\n",
    "        Ks = []\n",
    "        us = []\n",
    "        Ts = []\n",
    "\n",
    "        all_days = sorted(list(train_data.keys()))\n",
    "        for day in all_days:\n",
    "            # get observable data\n",
    "            ## Stock Wise and market wise data\n",
    "            r_t = train_data[day][1] \n",
    "            u_t = train_data[day][2].reshape([-1]) * math.sqrt(bday_p_year)\n",
    "            p_t = train_data[day][3]\n",
    "\n",
    "            ## Option wise data\n",
    "            y_t = train_data[day][0][\"spotclose\"].values\n",
    "            K_t = train_data[day][0][\"strike_price\"].values\n",
    "            today = [d.date() for d in train_data[day][0][\"date\"]]\n",
    "            expireday = [d.date() for d in train_data[day][0][\"exdate\"]]\n",
    "            T_t = np.busday_count(today, expireday) / bday_p_year\n",
    "\n",
    "\n",
    "            ukf.predict(fx = ESNf, \n",
    "                        G_idx=G_idx, G_in_idx=G_in_idx, b_idx=b_idx, \n",
    "                        u_quad_now=np.power(u_t,2))\n",
    "            ukf.update(y_t, hx=BSf, \n",
    "                       G_idx=G_idx, G_in_idx=G_in_idx, b_idx=b_idx, \n",
    "                       p_t=p_t, r_t=r_t, K_t=K_t, T_t=T_t)\n",
    "            ms.append(ukf.x_post.copy())\n",
    "            Cs.append(ukf.P_post.copy())\n",
    "            u_quad_s.append(np.power(u_t,2))\n",
    "            us.append(u_t)\n",
    "            ps.append(p_t)\n",
    "            rs.append(r_t)\n",
    "            ys.append(y_t)\n",
    "            Ks.append(K_t)\n",
    "            Ts.append(T_t)\n",
    "\n",
    "        ms = np.array(ms)\n",
    "        Cs = np.array(Cs)\n",
    "        ms_s, Cs_s = ms, Cs\n",
    "        ms_s, Cs_s, _, cvs_s = ukf.rts_smoother_alternative(ms, Cs, fx=ESNf,\n",
    "                                                            G_idx=G_idx,\n",
    "                                                            G_in_idx=G_in_idx,\n",
    "                                                            b_idx=b_idx,\n",
    "                                                            u_quad_s=u_quad_s)\n",
    "        \n",
    "        num_to_average = 10\n",
    "        theta_last_m = ms_s[-1][:G_idx]\n",
    "        theta_last_C = Cs_s[-1][:G_idx, :G_idx]\n",
    "        weight_last_m = np.array(ms_s[-num_to_average:])[:, G_idx:]\n",
    "        weight_last_C = np.array(Cs_s[-num_to_average:])[:, G_idx:, G_idx:]\n",
    "        avg_weight_last_m = np.average(weight_last_m, axis=0)\n",
    "        avg_weight_last_C = np.average(weight_last_C, axis=0)\n",
    "        ukf.x = np.concatenate((theta_last_m, avg_weight_last_m))  # initial state\n",
    "        ukf.P = block_diag(theta_last_C, avg_weight_last_C)  # initial uncertainty        \n",
    "        \n",
    "    ################################################################### Validation Performance\n",
    "        valid_errors = []\n",
    "\n",
    "        all_valid_days = sorted(list(valid_data.keys()))\n",
    "        for day in all_valid_days:\n",
    "            # get observable data\n",
    "            ## Stock Wise and market wise data\n",
    "            r_t = valid_data[day][1]\n",
    "            u_t = valid_data[day][2].reshape([-1]) * math.sqrt(bday_p_year)\n",
    "            p_t = valid_data[day][3]\n",
    "\n",
    "            ## Option wise data\n",
    "            y_t = valid_data[day][0][\"spotclose\"].values\n",
    "            K_t = valid_data[day][0][\"strike_price\"].values\n",
    "            today = [d.date() for d in valid_data[day][0][\"date\"]]\n",
    "            expireday = [d.date() for d in valid_data[day][0][\"exdate\"]]\n",
    "            T_t = np.busday_count(today, expireday) / bday_p_year\n",
    "\n",
    "            ukf.predict(fx = ESNf, \n",
    "                        G_idx=G_idx, G_in_idx=G_in_idx, b_idx=b_idx, \n",
    "                        u_quad_now=np.power(u_t,2))\n",
    "            pred_price = BSf(ukf.x_prior, \n",
    "                             G_idx=G_idx, G_in_idx=G_in_idx, b_idx=b_idx, \n",
    "                             p_t=p_t, r_t=r_t, K_t=K_t, T_t=T_t)\n",
    "\n",
    "            error = np.average(np.abs(y_t-pred_price) /y_t)\n",
    "            valid_errors.append(error)\n",
    "\n",
    "            ukf.update(y_t, hx=BSf,\n",
    "                       G_idx=G_idx, G_in_idx=G_in_idx, b_idx=b_idx,\n",
    "                       p_t=p_t, r_t=r_t, K_t=K_t, T_t=T_t)\n",
    "\n",
    "        avg_valid_error = np.average(valid_errors) \n",
    "\n",
    "    ################################################################### Testing Performance\n",
    "\n",
    "        # forward K step prediction\n",
    "        k_step_test_error = []\n",
    "\n",
    "        for k in range(1, min(forward_k+1, num_test_day+1)):\n",
    "\n",
    "            test_errors = []\n",
    "\n",
    "\n",
    "            all_test_days = sorted(list(test_data.keys()))\n",
    "\n",
    "            # For loop for base shift, shift of last updated ukf timestep\n",
    "            for idx in range(len(all_test_days) - k):\n",
    "\n",
    "                ukf_pred = copy.deepcopy(ukf)\n",
    "\n",
    "                # For loop for k predictions forward\n",
    "                for shift in range(k) :\n",
    "                    # get observable data\n",
    "                    ## Stock Wise and market wise data\n",
    "                    r_t = test_data[all_test_days[idx+shift]][1] \n",
    "                    u_t = test_data[all_test_days[idx+shift]][2].reshape([-1]) * math.sqrt(bday_p_year)\n",
    "                    p_t = test_data[all_test_days[idx+shift]][3]\n",
    "\n",
    "                    ## Option wise data\n",
    "                    y_t = test_data[all_test_days[idx+shift]][0][\"spotclose\"].values\n",
    "                    K_t = test_data[all_test_days[idx+shift]][0][\"strike_price\"].values\n",
    "                    today = [d.date() for d in test_data[all_test_days[idx+shift]][0][\"date\"]]\n",
    "                    expireday = [d.date() for d in test_data[all_test_days[idx+shift]][0][\"exdate\"]]\n",
    "                    T_t = np.busday_count(today, expireday) / bday_p_year\n",
    "\n",
    "                    ukf_pred.predict(fx = ESNf, \n",
    "                                     G_idx=G_idx, G_in_idx=G_in_idx, b_idx=b_idx, \n",
    "                                     u_quad_now=np.power(u_t,2))\n",
    "\n",
    "\n",
    "\n",
    "                pred_price = BSf(ukf_pred.x_prior, \n",
    "                                 G_idx=G_idx, G_in_idx=G_in_idx, b_idx=b_idx,\n",
    "                                 p_t=p_t, r_t=r_t, K_t=K_t, T_t=T_t)\n",
    "                error = np.average(np.abs(y_t-pred_price) /y_t)\n",
    "                test_errors.append(error)\n",
    "\n",
    "\n",
    "                # shift base one step forward\n",
    "                r_t = test_data[all_test_days[idx]][1]\n",
    "                u_t = test_data[all_test_days[idx]][2].reshape([-1]) * math.sqrt(bday_p_year)\n",
    "                p_t = test_data[all_test_days[idx]][3]\n",
    "\n",
    "                ## Option wise data\n",
    "                y_t = test_data[all_test_days[idx]][0][\"spotclose\"].values\n",
    "                K_t = test_data[all_test_days[idx]][0][\"strike_price\"].values\n",
    "                today = [d.date() for d in test_data[all_test_days[idx]][0][\"date\"]]\n",
    "                expireday = [d.date() for d in test_data[all_test_days[idx]][0][\"exdate\"]]\n",
    "                T_t = np.busday_count(today, expireday) / bday_p_year\n",
    "\n",
    "                ukf.predict(fx = ESNf, \n",
    "                            G_idx=G_idx, G_in_idx=G_in_idx, b_idx=b_idx,\n",
    "                            u_quad_now=np.power(u_t,2))\n",
    "                ukf.update(y_t, hx=BSf, \n",
    "                           G_idx=G_idx, G_in_idx=G_in_idx, b_idx=b_idx,\n",
    "                           p_t=p_t, r_t=r_t, K_t=K_t, T_t=T_t)\n",
    "\n",
    "            if test_errors != []:\n",
    "                avg_test_error = np.average(test_errors)\n",
    "                k_step_test_error.append(avg_test_error)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        \n",
    "        print(\"B&F {:2} | Valid Error {:.4f} | Test 1-Error {:.4f} | Test Max-Error {:.4f} \".format(forward_backward_itr,\n",
    "                                                                                                    avg_valid_error, \n",
    "                                                                                                    k_step_test_error[0],\n",
    "                                                                                                    k_step_test_error[-1]))\n",
    "            \n",
    "        ukf = UnscentedKalmanFilter(dim_x=total_dim, dim_z=topK, dt=1, fx=fx, hx=hx, points=points)\n",
    "\n",
    "#=============================== Circular Online Training ================================\n",
    "#\n",
    "        theta_first_m = ms_s[0][:G_idx]\n",
    "        weight_last_m = ms_s[-1][G_idx:]\n",
    "        theta_first_C = Cs_s[0][:G_idx, :G_idx]\n",
    "        weight_last_C = Cs_s[-1][G_idx:, G_idx:]\n",
    "        ukf.x = np.concatenate((theta_first_m, avg_weight_last_m))  # initial state\n",
    "        ukf.P = block_diag(theta_first_C, avg_weight_last_C)  # initial uncertainty\n",
    "#\n",
    "#=============================== In-order Online Training ================================\n",
    "#\n",
    "#         ukf.x = ms_s[0]  # np.concatenate((theta_first_m, weight_last_m))  # initial state\n",
    "#         ukf.P = Cs_s[0]  # block_diag(theta_first_C, weight_last_C)  # initial uncertainty\n",
    "#\n",
    "#=============================== Averages Online Training ================================\n",
    "#\n",
    "        \n",
    "\n",
    "#\n",
    "#         print(ukf.x[b_idx:])\n",
    "    \n",
    "    error_for_all_theta_dim.append(k_step_test_error)\n",
    "    \n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Prediction error vs forward step & Volatility trajectory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "for k in range(len(error_for_all_theta_dim)):\n",
    "\n",
    "    sns.set()\n",
    "    fig = plt.figure(figsize=(7, 4))\n",
    "    fig.suptitle('Prediction Error vs Forward Steps, theta_dim = {}'.format(k+theta_dim), color='C0')\n",
    "    \n",
    "\n",
    "    # forward steps\n",
    "    xlabel = list(range(len(k_step_test_error)+1))\n",
    "    plt.xticks(xlabel)\n",
    "    show = error_for_all_theta_dim[k]\n",
    "    plt.plot([i+1 for i in range(len(k_step_test_error))], show, marker='^', markersize= 5, linewidth=1)\n",
    "    fig.show()\n",
    "    \n",
    "    for i, p in enumerate(show):\n",
    "        print(\"{:2}-step error {:.4f}\".format(i+1, p))\n",
    "        \n",
    "    print(\"AVERAGE error {:.4f}\".format(np.average(show)))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
